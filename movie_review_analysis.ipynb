{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uzaTsdYmNaN03FbPeZFOZMsbptRHCYxu",
      "authorship_tag": "ABX9TyM51y6BINpBVwIPvfuXwFOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyje66/python_project/blob/main/movie_review_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEXYogz8EdB3"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U55sSHaHTboK"
      },
      "source": [
        "train_data=pd.read_csv('/content/drive/My Drive/Colab Notebooks/training_data1.csv', encoding='latin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rPc93q-TcLF"
      },
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGqIvISdUBNL"
      },
      "source": [
        "train_data = shuffle (train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ifLHM7vWtdq"
      },
      "source": [
        "newdata = pd.DataFrame({\"sentiment\":train_data.sentiment, \"review\":train_data.review})\n",
        "newdata.to_csv(\"/content/drive/My Drive/Colab Notebooks/人機互動/newdata.csv\", index=False)\n",
        "newdata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMJzCdI3ISyB",
        "outputId": "d5de9090-4953-40cd-8ac0-4d73ced3c927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "newdata=pd.read_csv('/content/drive/My Drive/Colab Notebooks/人機互動/newdata.csv', encoding='latin')\n",
        "newdata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@posty Oh  You work in support too ??!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>@ewanspence Yay! I am not the only Eurovision ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@charlottekane I've tryed but none of it will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Passing thrugh Bmore, even though I don't wann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Hey babies! I had a loooooong day today so its...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          0            @posty Oh  You work in support too ??!!\n",
              "1          4  @ewanspence Yay! I am not the only Eurovision ...\n",
              "2          0  @charlottekane I've tryed but none of it will ...\n",
              "3          0  Passing thrugh Bmore, even though I don't wann...\n",
              "4          0  Hey babies! I had a loooooong day today so its..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdDtskokIOB5",
        "outputId": "341be1e1-71f0-49ee-85e8-3a87cfaf98b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "reviews=newdata['review']\n",
        "labels=newdata['sentiment']\n",
        "input_test=newdata['review']\n",
        "reviews = reviews[:943717]\n",
        "input_test = input_test[-104858:]\n",
        "y_test=list()\n",
        "print(reviews[-5:])\n",
        "print(input_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943712    @rupertg i have!  thy are rubbish!   No sugges...\n",
            "943713    mark just ate all my chocolate. booooooooooooo...\n",
            "943714    Summer school is boring already  life just isn...\n",
            "943715    So im going to sleep alone tonight.  SOMEONE c...\n",
            "943716    @Susan_BBA I just hope that our &quot;wonderfu...\n",
            "Name: review, dtype: object\n",
            "943717    @KristyDaubar well i c ur up early i just want...\n",
            "943718    @Chesterbear I'm fuckin shattered babe - god o...\n",
            "943719    watching tori &amp; dean. &amp; drinking a roc...\n",
            "943720           Back at my mums. Now doing Tech homework. \n",
            "943721    this week's not gonna be fun...esp starting it...\n",
            "Name: review, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB3BhP_RI0T4",
        "outputId": "c025c88a-2f21-447e-e8a1-1d1dd8a6dbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(reviews))\n",
        "print(len(input_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943717\n",
            "104858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJncRU_DbEfn"
      },
      "source": [
        "# (0 = negative, 4 = positive)\n",
        "labels=[1 if label == 4 else 0 for label in labels]  # 0-->negtive, 1-->positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jOA6RYTbNkI"
      },
      "source": [
        "labels_test = labels[-104858:]\n",
        "labels = labels[:943717]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtACxesMeDA3",
        "outputId": "b6985d61-d2da-4fc1-b7f4-3c52689e276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(labels[:5])\n",
        "print(labels[-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L24sgQ6GJJZc",
        "outputId": "4a2d544e-503d-4436-cd45-9c29d23da927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J1GyqJTLB3z",
        "outputId": "b13dd5d7-029b-4139-f208-aa6a2da3b329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VAAaF_NJuwt"
      },
      "source": [
        "appos = {\n",
        "\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTo-KieaJW0e"
      },
      "source": [
        "from string import punctuation\n",
        "def review_formatting(reviews):\n",
        "    all_reviews=list()\n",
        "    for text in reviews:\n",
        "        lower_case = text.lower()\n",
        "        words = lower_case.split()\n",
        "        reformed = [appos[word] if word in appos else word for word in words]\n",
        "        reformed_test=list()\n",
        "        for word in reformed:\n",
        "            if word not in stop_words:\n",
        "                reformed_test.append(word)\n",
        "        reformed = \" \".join(reformed_test) \n",
        "        punct_text = \"\".join([ch for ch in reformed if ch not in punctuation])\n",
        "        all_reviews.append(punct_text)\n",
        "    all_text = \" \".join(all_reviews)\n",
        "    all_words = all_text.split()\n",
        "    return all_reviews, all_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XYZHYWPKFvO"
      },
      "source": [
        "from collections import Counter \n",
        "# Count all the words using Counter Method\n",
        "all_reviews, all_words=review_formatting(reviews)\n",
        "count_words = Counter(all_words)\n",
        "total_words=len(all_words)\n",
        "sorted_words=count_words.most_common(total_words)\n",
        "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHmjj7Q5oEre",
        "outputId": "b1cc3cad-39bc-4cec-a27e-f6abac19973e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(vocab_to_int['a'])  # 'a' = 1544"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWLKmzuYKVmP"
      },
      "source": [
        "def encode_reviews(reviews):\n",
        "    \"\"\"\n",
        "    encode_reviews function will encodes review in to array of numbers\n",
        "    \"\"\"\n",
        "    all_reviews=list()\n",
        "    for text in reviews:\n",
        "        text = text.lower()\n",
        "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "        all_reviews.append(text)\n",
        "    encoded_reviews=list()\n",
        "    for review in all_reviews:\n",
        "        encoded_review=list()\n",
        "        for word in review.split():\n",
        "            if word not in vocab_to_int.keys():\n",
        "                encoded_review.append(0)\n",
        "            else:\n",
        "                encoded_review.append(vocab_to_int[word])\n",
        "        encoded_reviews.append(encoded_review)\n",
        "    return encoded_reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD70tuItMOFA"
      },
      "source": [
        "def pad_sequences(encoded_reviews, sequence_length=20):\n",
        "    ''' \n",
        "    Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
        "    \n",
        "    for i, review in enumerate(encoded_reviews):\n",
        "        review_len=len(review)\n",
        "        if (review_len<=sequence_length):\n",
        "            zeros=list(np.zeros(sequence_length-review_len))\n",
        "            new=zeros+review\n",
        "        else:\n",
        "            new=review[:sequence_length]\n",
        "        features[i,:]=np.array(new)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhaRGnQMXir"
      },
      "source": [
        "def preprocess(reviews):\n",
        "    \"\"\"\n",
        "    This Function will tranform reviews in to model readable form\n",
        "    \"\"\"\n",
        "    formated_reviews, all_words = review_formatting(reviews)\n",
        "    encoded_reviews=encode_reviews(formated_reviews)\n",
        "    features=pad_sequences(encoded_reviews, 20)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tta4pJFJMajS",
        "outputId": "82af1e7f-5010-41c6-9d39-08b23623687d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "encoded_reviews=encode_reviews(reviews)\n",
        "review_len=[len(encoded_review) for encoded_review in encoded_reviews]\n",
        "pd.Series(review_len).hist()\n",
        "plt.show()\n",
        "pd.Series(review_len).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    943717.000000\n",
              "mean         13.272228\n",
              "std           6.971069\n",
              "min           1.000000\n",
              "25%           7.000000\n",
              "50%          12.000000\n",
              "75%          19.000000\n",
              "max         111.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsMB-ktZOlyu",
        "outputId": "86913628-b88e-4e1c-8c77-e1cbd50642dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(labels[-5:])\n",
        "print(type(labels))\n",
        "labels = np.array(labels)\n",
        "labels_test = np.array(labels_test)\n",
        "print(type(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0]\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY5Q_tFyMirF",
        "outputId": "aad62cfc-cd43-44b7-940a-f699e585dcb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
        "features=preprocess(reviews)\n",
        "train_x=features[:int(0.90*len(features))]\n",
        "train_y=labels[:int(0.90*len(features))]\n",
        "#train_x=features\n",
        "#train_y=labels\n",
        "valid_x=features[int(0.90*len(features)):]\n",
        "valid_y=labels[int(0.90*len(features)):]\n",
        "print(len(train_y), len(valid_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "849345 94372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb7vnkQpxE3H",
        "outputId": "0cd041f6-0a79-4127-d8b3-58446ae1ccbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "valid_x[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,  3975,  2571,   369,  4768,  1213,  5580,\n",
              "         5580,   381],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,    24,    10,    72,  5163,   225,\n",
              "        16430,  6954],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,  2695,  9702,   845,\n",
              "        23816,   428],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,   836,   285,   133,    35,\n",
              "         2554,   234],\n",
              "       [    0,     0,     0,     0,     0,   123,   461,  8290,    15,\n",
              "          225,  2811,  2516,    69,   722,   270,   102,   225,  1391,\n",
              "          157,   523]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVPVKj83NARs"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#create Tensor Dataset\n",
        "train_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "\n",
        "#dataloader\n",
        "batch_size=512\n",
        "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18V6h1osPUk5",
        "outputId": "f2c48259-5034-46dc-b528-8d269f2e1024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)                 # 等價於 for data in dataloader:\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([512, 20])\n",
            "Sample input: \n",
            " tensor([[     0,      0,      0,  ...,      4,    536,    577],\n",
            "        [     0,      0,      0,  ...,    107,    649,    176],\n",
            "        [     0,      0,      0,  ...,    154,    188, 139559],\n",
            "        ...,\n",
            "        [     0,      0,    150,  ...,      4,    178,   2995],\n",
            "        [     0,      0,      0,  ...,     49,    204, 242278],\n",
            "        [     0,      0,      0,  ...,    145,    102,    211]])\n",
            "\n",
            "Sample label size:  torch.Size([512])\n",
            "Sample label: \n",
            " tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
            "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBsST-zeBCqE"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igDztz4sPbQk"
      },
      "source": [
        "class SentimentalLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
        "        super().__init__()\n",
        "        self.output_size=output_size\n",
        "        self.n_layers=n_layers\n",
        "        self.hidden_dim=hidden_dim\n",
        "        #Embedding and LSTM layers\n",
        "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        #dropout layer\n",
        "        self.dropout=nn.Dropout(0.3)\n",
        "        #Linear and sigmoid layer\n",
        "        self.fc1=nn.Linear(hidden_dim, 64)\n",
        "        self.fc2=nn.Linear(64, 16)\n",
        "        self.fc3=nn.Linear(16,output_size)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        batch_size=x.size()\n",
        "        #Embadding and LSTM output\n",
        "        embedd=self.embedding(x)\n",
        "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
        "        #stack up the lstm output\n",
        "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        #dropout and fully connected layers\n",
        "        out=self.dropout(lstm_out)\n",
        "        out=self.fc1(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc2(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc3(out)\n",
        "        sig_out=self.sigmoid(out)\n",
        "        sig_out=sig_out.view(batch_size, -1)\n",
        "        sig_out=sig_out[:, -1]\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X52xNX5ePiXi",
        "outputId": "1f9aec96-3ad8-4f58-88f0-01613727ffd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentalLSTM(\n",
            "  (embedding): Embedding(550792, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sn5kn-4JeRa"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62XfWPA6Pl2Y",
        "outputId": "968a38a7-e440-4f48-98aa-9f182addb50e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "# train for some number of epochs\n",
        "correct_train = 0\n",
        "counter = 0\n",
        "net.train()\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        if(train_on_gpu):\n",
        "            inputs=inputs.cuda()\n",
        "            labels=labels.cuda()\n",
        "        h = tuple([each.data for each in h])\n",
        "        net.zero_grad()\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "        \n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        # compare predictions to true label\n",
        "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "        correct_train += np.sum(correct)\n",
        "        \n",
        "        \n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()  \n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "            train_acc = correct_train / len(train_loader.dataset)\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Train Acc: {:.2f}%...\".format(train_acc*100),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "    correct_train = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3... Step: 100... Loss: 0.432317... Train Acc: 4.67%... Val Loss: 0.446252\n",
            "Epoch: 1/3... Step: 200... Loss: 0.447014... Train Acc: 9.55%... Val Loss: 0.416293\n",
            "Epoch: 1/3... Step: 300... Loss: 0.437001... Train Acc: 14.47%... Val Loss: 0.402344\n",
            "Epoch: 1/3... Step: 400... Loss: 0.375438... Train Acc: 19.42%... Val Loss: 0.393491\n",
            "Epoch: 1/3... Step: 500... Loss: 0.430828... Train Acc: 24.38%... Val Loss: 0.388737\n",
            "Epoch: 1/3... Step: 600... Loss: 0.412552... Train Acc: 29.37%... Val Loss: 0.382603\n",
            "Epoch: 1/3... Step: 700... Loss: 0.361553... Train Acc: 34.38%... Val Loss: 0.379901\n",
            "Epoch: 1/3... Step: 800... Loss: 0.315434... Train Acc: 39.39%... Val Loss: 0.376010\n",
            "Epoch: 1/3... Step: 900... Loss: 0.370120... Train Acc: 44.41%... Val Loss: 0.374574\n",
            "Epoch: 1/3... Step: 1000... Loss: 0.343544... Train Acc: 49.44%... Val Loss: 0.373263\n",
            "Epoch: 1/3... Step: 1100... Loss: 0.343581... Train Acc: 54.48%... Val Loss: 0.373230\n",
            "Epoch: 1/3... Step: 1200... Loss: 0.364545... Train Acc: 59.52%... Val Loss: 0.366141\n",
            "Epoch: 1/3... Step: 1300... Loss: 0.382774... Train Acc: 64.58%... Val Loss: 0.366296\n",
            "Epoch: 1/3... Step: 1400... Loss: 0.394989... Train Acc: 69.63%... Val Loss: 0.363908\n",
            "Epoch: 1/3... Step: 1500... Loss: 0.378573... Train Acc: 74.69%... Val Loss: 0.362050\n",
            "Epoch: 1/3... Step: 1600... Loss: 0.363872... Train Acc: 79.75%... Val Loss: 0.362282\n",
            "Epoch: 2/3... Step: 1700... Loss: 0.344273... Train Acc: 2.19%... Val Loss: 0.366420\n",
            "Epoch: 2/3... Step: 1800... Loss: 0.280655... Train Acc: 7.39%... Val Loss: 0.374722\n",
            "Epoch: 2/3... Step: 1900... Loss: 0.345155... Train Acc: 12.60%... Val Loss: 0.365561\n",
            "Epoch: 2/3... Step: 2000... Loss: 0.340519... Train Acc: 17.81%... Val Loss: 0.367547\n",
            "Epoch: 2/3... Step: 2100... Loss: 0.305247... Train Acc: 23.02%... Val Loss: 0.370650\n",
            "Epoch: 2/3... Step: 2200... Loss: 0.334332... Train Acc: 28.22%... Val Loss: 0.367565\n",
            "Epoch: 2/3... Step: 2300... Loss: 0.310260... Train Acc: 33.43%... Val Loss: 0.367427\n",
            "Epoch: 2/3... Step: 2400... Loss: 0.285316... Train Acc: 38.64%... Val Loss: 0.365293\n",
            "Epoch: 2/3... Step: 2500... Loss: 0.305732... Train Acc: 43.84%... Val Loss: 0.365237\n",
            "Epoch: 2/3... Step: 2600... Loss: 0.273853... Train Acc: 49.05%... Val Loss: 0.365384\n",
            "Epoch: 2/3... Step: 2700... Loss: 0.314109... Train Acc: 54.26%... Val Loss: 0.365182\n",
            "Epoch: 2/3... Step: 2800... Loss: 0.301534... Train Acc: 59.47%... Val Loss: 0.361903\n",
            "Epoch: 2/3... Step: 2900... Loss: 0.319549... Train Acc: 64.68%... Val Loss: 0.362177\n",
            "Epoch: 2/3... Step: 3000... Loss: 0.318572... Train Acc: 69.91%... Val Loss: 0.365489\n",
            "Epoch: 2/3... Step: 3100... Loss: 0.285455... Train Acc: 75.12%... Val Loss: 0.363893\n",
            "Epoch: 2/3... Step: 3200... Loss: 0.287653... Train Acc: 80.32%... Val Loss: 0.357065\n",
            "Epoch: 2/3... Step: 3300... Loss: 0.322727... Train Acc: 85.55%... Val Loss: 0.362118\n",
            "Epoch: 3/3... Step: 3400... Loss: 0.254823... Train Acc: 4.56%... Val Loss: 0.386207\n",
            "Epoch: 3/3... Step: 3500... Loss: 0.225691... Train Acc: 10.00%... Val Loss: 0.391723\n",
            "Epoch: 3/3... Step: 3600... Loss: 0.276810... Train Acc: 15.41%... Val Loss: 0.381998\n",
            "Epoch: 3/3... Step: 3700... Loss: 0.256295... Train Acc: 20.83%... Val Loss: 0.399789\n",
            "Epoch: 3/3... Step: 3800... Loss: 0.274761... Train Acc: 26.24%... Val Loss: 0.405265\n",
            "Epoch: 3/3... Step: 3900... Loss: 0.241904... Train Acc: 31.65%... Val Loss: 0.396564\n",
            "Epoch: 3/3... Step: 4000... Loss: 0.259371... Train Acc: 37.05%... Val Loss: 0.393179\n",
            "Epoch: 3/3... Step: 4100... Loss: 0.275787... Train Acc: 42.45%... Val Loss: 0.385234\n",
            "Epoch: 3/3... Step: 4200... Loss: 0.214333... Train Acc: 47.86%... Val Loss: 0.386580\n",
            "Epoch: 3/3... Step: 4300... Loss: 0.246972... Train Acc: 53.26%... Val Loss: 0.391014\n",
            "Epoch: 3/3... Step: 4400... Loss: 0.252111... Train Acc: 58.66%... Val Loss: 0.382630\n",
            "Epoch: 3/3... Step: 4500... Loss: 0.252933... Train Acc: 64.06%... Val Loss: 0.397392\n",
            "Epoch: 3/3... Step: 4600... Loss: 0.250937... Train Acc: 69.44%... Val Loss: 0.394686\n",
            "Epoch: 3/3... Step: 4700... Loss: 0.265923... Train Acc: 74.83%... Val Loss: 0.383746\n",
            "Epoch: 3/3... Step: 4800... Loss: 0.246827... Train Acc: 80.22%... Val Loss: 0.391340\n",
            "Epoch: 3/3... Step: 4900... Loss: 0.260130... Train Acc: 85.62%... Val Loss: 0.384118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEH6UK7snBaf",
        "outputId": "37ec58c2-7a30-4b57-db88-f7d95b815c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels_test = np.array(labels_test)\n",
        "features_test = preprocess(input_test)\n",
        "test_x = features_test\n",
        "test_y = labels_test\n",
        "print(len(test_y))\n",
        "test_data=TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KuTx5GjxP00",
        "outputId": "2be98693-d3ce-4343-d8c3-8acd5258d6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_y[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFSW9weN_mKw",
        "outputId": "2f26e4bc-1d0e-4e70-9778-8d2d6878f0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.388\n",
            "Test accuracy: 0.835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbjtXsGhhgxr"
      },
      "source": [
        "torch.save(net.state_dict(), \"/content/drive/My Drive/Colab Notebooks/人機互動/model_state_dict.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RTkNnPjjA3q",
        "outputId": "dbf0f4f3-c1a0-496f-e3d4-9f1f3d74a1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "torch.save(net, \"/content/drive/My Drive/Colab Notebooks/人機互動/model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type SentimentalLSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWZrXIb0jRXg",
        "outputId": "f19193b9-be6c-4dbc-c3fa-6671f9374c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "call_model = torch.load(\"/content/drive/My Drive/Colab Notebooks/人機互動/model.pth\")\n",
        "call_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentalLSTM(\n",
              "  (embedding): Embedding(550694, 400)\n",
              "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24zhIjb_Eh9"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6emkjWNl_aFQ",
        "outputId": "cb2da79b-80b8-478f-b981-3a521d540a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = call_model(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1b4b496deb4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 6 were given"
          ]
        }
      ]
    }
  ]
}